{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QYO-HYkgZ4T3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.optim import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.metrics import roc_auc_score, precision_recall_curve, f1_score"
      ],
      "metadata": {
        "id": "VdpcwaM9z4TN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "IXpOCHEN2KAU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lEomYw8aQbh",
        "outputId": "1f147fec-65d9-4e59-c0fe-f1c889391dbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "=====================Data preparation============================="
      ],
      "metadata": {
        "id": "5Q9MHkvXys9q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JEb6Fm_HcbCy"
      },
      "outputs": [],
      "source": [
        "# -----------------\n",
        "# Helper: stratified sampling\n",
        "# -----------------\n",
        "def stratified_sample(df, target_col, frac=None, n=None, random_state=42):\n",
        "    \"\"\"Return stratified sample keeping target ratio\"\"\"\n",
        "    if frac is not None:\n",
        "        df_sampled = df.groupby(target_col, group_keys=False)\\\n",
        "                       .apply(lambda x: x.sample(frac=frac, random_state=random_state))\n",
        "    elif n is not None:\n",
        "        class_counts = df[target_col].value_counts()\n",
        "        total = class_counts.sum()\n",
        "        df_sampled = []\n",
        "        for c, count in class_counts.items():\n",
        "            take = int(n * (count / total))\n",
        "            df_sampled.append(df[df[target_col] == c].sample(n=take, random_state=random_state))\n",
        "        df_sampled = pd.concat(df_sampled)\n",
        "    else:\n",
        "        df_sampled = df\n",
        "    return df_sampled.sample(frac=1.0, random_state=random_state).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = \"B\"\n",
        "\n",
        "if dataset == \"A\":\n",
        "  dataset_name = \"/content/drive/MyDrive/wustl_iiot_2021.csv\"\n",
        "  target = 'Target'\n",
        "  drop_cols = [\"StartTime\", \"LastTime\", \"Traffic\", \"SrcAddr\", \"DstAddr\"]\n",
        "  frac=0.1\n",
        "elif dataset == \"B\":\n",
        "  dataset_name = \"/content/drive/MyDrive/creditcard.csv\"\n",
        "  target = 'Class'\n",
        "  drop_cols = [\"Time\"]\n",
        "  frac=0.5"
      ],
      "metadata": {
        "id": "gk0zY-nQcDoX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqQUooD0aAPH",
        "outputId": "46e8d4f5-6ec6-46d8-c52c-23dc6bbb65bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape: (284807, 30), anomaly ratio=0.1727%\n",
            "Sampled dataset shape: (142404, 30), anomaly ratio=0.1727%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2184620091.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda x: x.sample(frac=frac, random_state=random_state))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (75948, 30), anomaly ratio=0.1725%\n",
            "Valid shape: (37975, 30), anomaly ratio=0.1738%\n",
            "Test shape:  (28481, 30),  anomaly ratio=0.1720%\n",
            "['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n",
            "['Set']\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(dataset_name)\n",
        "\n",
        "df = df.drop(columns=[c for c in drop_cols if c in df.columns])\n",
        "\n",
        "\n",
        "print(f\"Original dataset shape: {df.shape}, anomaly ratio={df[target].mean():.4%}\")\n",
        "\n",
        "# Stratified sampling\n",
        "df_sampled = stratified_sample(df, target, frac=frac, random_state=0)\n",
        "print(f\"Sampled dataset shape: {df_sampled.shape}, anomaly ratio={df_sampled[target].mean():.4%}\")\n",
        "\n",
        "df_sampled = df_sampled.reset_index(drop=True)\n",
        "\n",
        "features = df_sampled.columns\n",
        "\n",
        "train_df, test_df = train_test_split(\n",
        "    df_sampled, test_size=0.2, stratify=df_sampled[target], random_state=0\n",
        ")\n",
        "\n",
        "train_df, valid_df = train_test_split(\n",
        "    train_df, test_size= 0.2 / 0.6, stratify=train_df[target], random_state=0\n",
        ")\n",
        "\n",
        "print(f\"Train shape: {train_df.shape}, anomaly ratio={train_df[target].mean():.4%}\")\n",
        "print(f\"Valid shape: {valid_df.shape}, anomaly ratio={valid_df[target].mean():.4%}\")\n",
        "print(f\"Test shape:  {test_df.shape},  anomaly ratio={test_df[target].mean():.4%}\")\n",
        "\n",
        "# Add the \"Set\" column\n",
        "train_df[\"Set\"] = \"train\"\n",
        "valid_df[\"Set\"] = \"valid\"\n",
        "test_df[\"Set\"] = \"test\"\n",
        "\n",
        "# Combine them back together\n",
        "train = pd.concat([train_df, valid_df, test_df]).reset_index(drop=True)\n",
        "\n",
        "train_indices = train[train.Set == \"train\"].index\n",
        "valid_indices = train[train.Set == \"valid\"].index\n",
        "test_indices = train[train.Set == \"test\"].index\n",
        "\n",
        "\n",
        "categorical_columns = []\n",
        "categorical_dims = {}\n",
        "\n",
        "nunique = train.nunique()\n",
        "types = train.dtypes\n",
        "\n",
        "for col in train.columns:\n",
        "    if types[col] == 'object':\n",
        "        l_enc = LabelEncoder()\n",
        "        train[col] = train[col].fillna(\"VV_likely\")\n",
        "        train[col] = l_enc.fit_transform(train[col].values)\n",
        "        categorical_columns.append(col)\n",
        "        categorical_dims[col] = len(l_enc.classes_)\n",
        "    else:\n",
        "        train.fillna(train.loc[train_indices, col].mean(), inplace=True)\n",
        "\n",
        "unused_feat = [\"Set\"]\n",
        "\n",
        "features = [col for col in df_sampled.columns if col not in unused_feat + [target]]\n",
        "\n",
        "print(features)\n",
        "\n",
        "cat_idxs = [i for i, f in enumerate(features) if f in categorical_columns]\n",
        "\n",
        "cat_dims = [categorical_dims[f] for i, f in enumerate(features) if f in categorical_columns]\n",
        "\n",
        "print(categorical_columns)\n",
        "print(cat_dims)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_enc = LabelEncoder()\n",
        "train[target] = target_enc.fit_transform(train[target].values)"
      ],
      "metadata": {
        "id": "c-yxDUQHxt6F"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oXFTqW5IblTA"
      },
      "outputs": [],
      "source": [
        "X_train = train[features].values[train_indices]\n",
        "y_train = train[target].values[train_indices]\n",
        "\n",
        "X_valid = train[features].values[valid_indices]\n",
        "y_valid = train[target].values[valid_indices]\n",
        "\n",
        "X_test = train[features].values[test_indices]\n",
        "y_test = train[target].values[test_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XEizQZmXgxQm"
      },
      "outputs": [],
      "source": [
        "# Split the data into categorical and continuous parts\n",
        "X_train_categ = torch.tensor(X_train[:, cat_idxs], dtype=torch.long)\n",
        "X_train_cont = torch.tensor(np.delete(X_train, cat_idxs, axis=1), dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "\n",
        "X_valid_categ = torch.tensor(X_valid[:, cat_idxs], dtype=torch.long)\n",
        "X_valid_cont = torch.tensor(np.delete(X_valid, cat_idxs, axis=1), dtype=torch.float32)\n",
        "y_valid_tensor = torch.tensor(y_valid, dtype=torch.long)\n",
        "\n",
        "X_test_categ = torch.tensor(X_test[:, cat_idxs], dtype=torch.long)\n",
        "X_test_cont = torch.tensor(np.delete(X_test, cat_idxs, axis=1), dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_dataset = TensorDataset(X_train_categ, X_train_cont, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "valid_dataset = TensorDataset(X_valid_categ, X_valid_cont, y_valid_tensor)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "test_dataset = TensorDataset(X_test_categ, X_test_cont, y_test_tensor)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "======================================================================"
      ],
      "metadata": {
        "id": "6t0AMSr8y2Pe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "==================================Model================================"
      ],
      "metadata": {
        "id": "Lbv9mESCyQNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, einsum\n",
        "\n",
        "from einops import rearrange"
      ],
      "metadata": {
        "id": "t9qv3vmlzpQx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def exists(val):\n",
        "    return val is not None\n",
        "\n",
        "def default(val, d):\n",
        "    return val if exists(val) else d\n",
        "\n",
        "# classes\n",
        "\n",
        "class Residual(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(x, **kwargs) + x\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(self.norm(x), **kwargs)\n",
        "\n",
        "# attention\n",
        "\n",
        "class GEGLU(nn.Module):\n",
        "    def forward(self, x):\n",
        "        x, gates = x.chunk(2, dim = -1)\n",
        "        return x * F.gelu(gates)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, mult = 4, dropout = 0.):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, dim * mult * 2),\n",
        "            GEGLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(dim * mult, dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.net(x)\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        heads = 8,\n",
        "        dim_head = 16,\n",
        "        dropout = 0.\n",
        "    ):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head * heads\n",
        "        self.heads = heads\n",
        "        self.scale = dim_head ** -0.5\n",
        "\n",
        "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
        "        self.to_out = nn.Linear(inner_dim, dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.heads\n",
        "        q, k, v = self.to_qkv(x).chunk(3, dim = -1)\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), (q, k, v))\n",
        "        sim = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale\n",
        "\n",
        "        attn = sim.softmax(dim = -1)\n",
        "        dropped_attn = self.dropout(attn)\n",
        "\n",
        "        out = einsum('b h i j, b h j d -> b h i d', dropped_attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)', h = h)\n",
        "        return self.to_out(out), attn\n",
        "\n",
        "# transformer\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, num_tokens, dim, depth, heads, dim_head, attn_dropout, ff_dropout):\n",
        "        super().__init__()\n",
        "        self.embeds = nn.Embedding(num_tokens, dim)\n",
        "        self.layers = nn.ModuleList([])\n",
        "\n",
        "        for _ in range(depth):\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                PreNorm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = attn_dropout)),\n",
        "                PreNorm(dim, FeedForward(dim, dropout = ff_dropout)),\n",
        "            ]))\n",
        "\n",
        "    def forward(self, x, return_attn = False):\n",
        "        x = self.embeds(x)\n",
        "\n",
        "        post_softmax_attns = []\n",
        "\n",
        "        for attn, ff in self.layers:\n",
        "            attn_out, post_softmax_attn = attn(x)\n",
        "            post_softmax_attns.append(post_softmax_attn)\n",
        "\n",
        "            x = x + attn_out\n",
        "            x = ff(x) + x\n",
        "\n",
        "        if not return_attn:\n",
        "            return x\n",
        "\n",
        "        return x, torch.stack(post_softmax_attns)\n",
        "# mlp\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, dims, act = None):\n",
        "        super().__init__()\n",
        "        dims_pairs = list(zip(dims[:-1], dims[1:]))\n",
        "        layers = []\n",
        "        for ind, (dim_in, dim_out) in enumerate(dims_pairs):\n",
        "            is_last = ind >= (len(dims_pairs) - 1)\n",
        "            linear = nn.Linear(dim_in, dim_out)\n",
        "            layers.append(linear)\n",
        "\n",
        "            if is_last:\n",
        "                continue\n",
        "\n",
        "            act = default(act, nn.ReLU())\n",
        "            layers.append(act)\n",
        "\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.mlp(x)\n",
        "\n",
        "# main class\n",
        "\n",
        "class TabTransformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        categories,\n",
        "        num_continuous,\n",
        "        dim,\n",
        "        depth,\n",
        "        heads,\n",
        "        dim_head = 16,\n",
        "        dim_out = 1,\n",
        "        mlp_hidden_mults = (4, 2),\n",
        "        mlp_act = None,\n",
        "        num_special_tokens = 2,\n",
        "        continuous_mean_std = None,\n",
        "        attn_dropout = 0.,\n",
        "        ff_dropout = 0.\n",
        "    ):\n",
        "        super().__init__()\n",
        "        assert all(map(lambda n: n > 0, categories)), 'number of each category must be positive'\n",
        "        assert len(categories) + num_continuous > 0, 'input shape must not be null'\n",
        "\n",
        "        # categories related calculations\n",
        "\n",
        "        self.num_categories = len(categories)\n",
        "        self.num_unique_categories = sum(categories)\n",
        "\n",
        "        # create category embeddings table\n",
        "\n",
        "        self.num_special_tokens = num_special_tokens\n",
        "        total_tokens = self.num_unique_categories + num_special_tokens\n",
        "\n",
        "        # for automatically offsetting unique category ids to the correct position in the categories embedding table\n",
        "\n",
        "        if self.num_unique_categories > 0:\n",
        "            categories_offset = F.pad(torch.tensor(list(categories)), (1, 0), value = num_special_tokens)\n",
        "            categories_offset = categories_offset.cumsum(dim = -1)[:-1]\n",
        "            self.register_buffer('categories_offset', categories_offset)\n",
        "\n",
        "        # continuous\n",
        "        self.num_continuous = num_continuous\n",
        "\n",
        "        if self.num_continuous > 0:\n",
        "            if exists(continuous_mean_std):\n",
        "                assert continuous_mean_std.shape == (num_continuous, 2), f'continuous_mean_std must have a shape of ({num_continuous}, 2) where the last dimension contains the mean and variance respectively'\n",
        "            self.register_buffer('continuous_mean_std', continuous_mean_std)\n",
        "\n",
        "            self.norm = nn.LayerNorm(num_continuous)\n",
        "\n",
        "\n",
        "        # transformer\n",
        "\n",
        "        self.transformer = Transformer(\n",
        "            num_tokens = total_tokens,\n",
        "            dim = dim,\n",
        "            depth = depth,\n",
        "            heads = heads,\n",
        "            dim_head = dim_head,\n",
        "            attn_dropout = attn_dropout,\n",
        "            ff_dropout = ff_dropout\n",
        "        )\n",
        "\n",
        "        # mlp to logits\n",
        "\n",
        "        input_size = (dim * self.num_categories) + num_continuous\n",
        "        l = input_size // 8\n",
        "\n",
        "        hidden_dimensions = list(map(lambda t: l * t, mlp_hidden_mults))\n",
        "        all_dimensions = [input_size, *hidden_dimensions, dim_out]\n",
        "\n",
        "        self.mlp = MLP(all_dimensions, act = mlp_act)\n",
        "\n",
        "    def forward(self, x_categ, x_cont, return_attn = False):\n",
        "        xs = []\n",
        "\n",
        "        assert x_categ.shape[-1] == self.num_categories, f'you must pass in {self.num_categories} values for your categories input'\n",
        "\n",
        "        if self.num_unique_categories > 0:\n",
        "            x_categ += self.categories_offset\n",
        "\n",
        "            x, attns = self.transformer(x_categ, return_attn = True)\n",
        "\n",
        "            flat_categ = x.flatten(1)\n",
        "            xs.append(flat_categ)\n",
        "\n",
        "        assert x_cont.shape[1] == self.num_continuous, f'you must pass in {self.num_continuous} values for your continuous input'\n",
        "\n",
        "        if self.num_continuous > 0:\n",
        "            if exists(self.continuous_mean_std):\n",
        "                mean, std = self.continuous_mean_std.unbind(dim = -1)\n",
        "                x_cont = (x_cont - mean) / std\n",
        "\n",
        "            normed_cont = self.norm(x_cont)\n",
        "            xs.append(normed_cont)\n",
        "\n",
        "        x = torch.cat(xs, dim = -1)\n",
        "        logits =self.mlp(x)\n",
        "\n",
        "        if not return_attn:\n",
        "            return logits\n",
        "\n",
        "        return logits, attns"
      ],
      "metadata": {
        "id": "5UmJ2xwyy-AA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "======================================================================="
      ],
      "metadata": {
        "id": "GQbua9hnyb3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define TabTransformer model\n",
        "model = TabTransformer(\n",
        "    categories=cat_dims,      # dimensions of categorical columns\n",
        "    num_continuous=len(features) - len(cat_dims), # number of continuous values\n",
        "    dim=32,\n",
        "    dim_out=2,                # binary classification\n",
        "    depth=6,\n",
        "    heads=8,\n",
        "    attn_dropout=0.1,\n",
        "    ff_dropout=0.1,\n",
        "    mlp_hidden_mults=(4, 2)\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "GP2nhw8Hx73H"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3️⃣ Optimizer and loss\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "# 4️⃣ Training loop with validation\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for x_categ, x_cont, y in train_loader:\n",
        "        x_categ = x_categ.to(device)\n",
        "        x_cont = x_cont.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(x_categ, x_cont)\n",
        "        loss = criterion(preds, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "    # 🔹 Validation step\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    all_val_preds = []\n",
        "    all_val_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_categ, x_cont, y in valid_loader:\n",
        "            x_categ = x_categ.to(device)\n",
        "            x_cont = x_cont.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            preds = model(x_categ, x_cont)\n",
        "            loss = criterion(preds, y)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            all_val_preds.extend(preds.argmax(dim=1).cpu().tolist())\n",
        "            all_val_labels.extend(y.cpu().tolist())\n",
        "\n",
        "    avg_val_loss = val_loss / len(valid_loader)\n",
        "    val_acc = accuracy_score(all_val_labels, all_val_preds)\n",
        "\n",
        "    print(f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OquETEtzzZ-V",
        "outputId": "2b7c67d7-079e-45c8-dc79-ab24b975e78e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10\n",
            "Train Loss: 0.0305 | Val Loss: 0.0068 | Val Acc: 0.9989\n",
            "\n",
            "Epoch 2/10\n",
            "Train Loss: 0.0054 | Val Loss: 0.0064 | Val Acc: 0.9989\n",
            "\n",
            "Epoch 3/10\n",
            "Train Loss: 0.0044 | Val Loss: 0.0066 | Val Acc: 0.9989\n",
            "\n",
            "Epoch 4/10\n",
            "Train Loss: 0.0042 | Val Loss: 0.0056 | Val Acc: 0.9989\n",
            "\n",
            "Epoch 5/10\n",
            "Train Loss: 0.0038 | Val Loss: 0.0055 | Val Acc: 0.9990\n",
            "\n",
            "Epoch 6/10\n",
            "Train Loss: 0.0036 | Val Loss: 0.0059 | Val Acc: 0.9990\n",
            "\n",
            "Epoch 7/10\n",
            "Train Loss: 0.0035 | Val Loss: 0.0056 | Val Acc: 0.9990\n",
            "\n",
            "Epoch 8/10\n",
            "Train Loss: 0.0032 | Val Loss: 0.0056 | Val Acc: 0.9991\n",
            "\n",
            "Epoch 9/10\n",
            "Train Loss: 0.0031 | Val Loss: 0.0058 | Val Acc: 0.9990\n",
            "\n",
            "Epoch 10/10\n",
            "Train Loss: 0.0031 | Val Loss: 0.0059 | Val Acc: 0.9990\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5️⃣ Final test evaluation\n",
        "model.eval()\n",
        "all_test_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x_categ, x_cont, _ in test_loader:\n",
        "        x_categ = x_categ.to(device)\n",
        "        x_cont = x_cont.to(device)\n",
        "\n",
        "        preds = model(x_categ, x_cont)\n",
        "        all_test_preds.extend(preds.argmax(dim=1).cpu().tolist())\n",
        "\n",
        "y_pred = np.array(all_test_preds)\n",
        "test_acc = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "print(f\"\\nFINAL TEST ACCURACY: {test_acc:.4f}\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnQJLebo4XbY",
        "outputId": "11a181e4-4490-43fa-ab22-72f10ebb89c5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "FINAL TEST ACCURACY: 0.9991\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     28432\n",
            "           1       0.76      0.71      0.74        49\n",
            "\n",
            "    accuracy                           1.00     28481\n",
            "   macro avg       0.88      0.86      0.87     28481\n",
            "weighted avg       1.00      1.00      1.00     28481\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "zGZ9KqXK0AiS",
        "outputId": "ff791663-c37f-4ddd-9c3f-26468818bd78"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy, Precision, Recall, F1-Score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print individual scores\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "# Classification report for a detailed overview\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEfIIcCr9tf9",
        "outputId": "e0edae91-2252-4332-804b-a14eb9adbf1d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9991\n",
            "Precision: 0.7609\n",
            "Recall: 0.7143\n",
            "F1-Score: 0.7368\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     28432\n",
            "           1       0.76      0.71      0.74        49\n",
            "\n",
            "    accuracy                           1.00     28481\n",
            "   macro avg       0.88      0.86      0.87     28481\n",
            "weighted avg       1.00      1.00      1.00     28481\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HCXiFEcUg_iR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}